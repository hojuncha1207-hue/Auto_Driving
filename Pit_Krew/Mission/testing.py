# -*- coding: utf-8 -*-
import cv2
import numpy as np
import serial
import time

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import AutonomousLibrary as al
import Function_Library as fl

# --- [ì„¤ì • ë° ìƒìˆ˜] ---
WIDTH, HEIGHT = 640, 480
LANE_WIDTH_PIXELS = 450
ARDUINO_PORT = 'COM3'  # ì•„ë‘ì´ë…¸ í¬íŠ¸ ë²ˆí˜¸ (ì¥ì¹˜ê´€ë¦¬ì í™•ì¸ í•„ìˆ˜)
BAUDRATE = 9600  # ì•„ë‘ì´ë…¸ ì½”ë“œì™€ ì†ë„ ì¼ì¹˜

# ROI ì¢Œí‘œ ì„¤ì •
left_roi_pts = np.float32([[50, 480], [260, 480], [150, 315], [60, 270]])
right_roi_pts = np.float32([[380, 480], [580, 480], [570, 270], [490, 315]])


# --- [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def apply_roi(frame, x_start, x_end, y_start, y_end):
    """ì„¤ì •ëœ ë²”ìœ„ ì™¸ì—ëŠ” ì „ë¶€ ê²€ì€ìƒ‰ìœ¼ë¡œ ì²˜ë¦¬"""
    mask = np.zeros_like(frame)
    # ë²”ìœ„ ì˜ˆì™¸ ì²˜ë¦¬
    h, w = frame.shape[:2]
    x_start, x_end = max(0, x_start), min(w, x_end)
    y_start, y_end = max(0, y_start), min(h, y_end)

    mask[y_start:y_end, x_start:x_end] = frame[y_start:y_end, x_start:x_end]
    return mask


# --- [ê¸°ëŠ¥ í™•ì¥ í´ë˜ìŠ¤] ---
class SmartCamera(fl.libCAMERA):
    def object_detection_with_pos(self, img, sample=0, mode="circle", print_enable=False):
        """ì‹ í˜¸ë“± ìƒ‰ìƒê³¼ Yì¢Œí‘œë¥¼ í•¨ê»˜ ë°˜í™˜"""
        result_color = "NONE"
        center_y = -1
        replica = img.copy()

        for color in (fl.RED, fl.YELLOW, fl.GREEN):
            extract = self.color_filtering(img, roi=color, print_enable=False)
            gray = self.gray_conversion(extract)
            circles = self.hough_transform(gray, mode=mode)

            if circles is not None:
                for circle in circles[0]:
                    center = (int(circle[0]), int(circle[1]))
                    radius = int(circle[2])
                    count = 0

                    hsv_img = self.hsv_conversion(img)
                    h, s, v = cv2.split(hsv_img)

                    for res in range(sample):
                        x = int(center[1] - sample / 2)
                        y = int(center[0] - sample / 2)
                        if x < 0 or x >= h.shape[0] or y < 0 or y >= h.shape[1]: continue

                        s_cond = s[x][y] > fl.SATURATION
                        if color == fl.RED:
                            h_cond = (h[x][y] < fl.HUE_THRESHOLD[color][0]) | (h[x][y] > fl.HUE_THRESHOLD[color][1])
                        else:
                            h_cond = (h[x][y] > fl.HUE_THRESHOLD[color][0]) & (h[x][y] < fl.HUE_THRESHOLD[color][1])

                        if h_cond and s_cond: count += 1

                    if count > sample / 2:
                        result_color = fl.COLOR[color]
                        center_y = center[1]
                        cv2.circle(replica, center, radius, (0, 0, 255), 2)
                        cv2.putText(replica, f"{result_color} y:{center_y}", (center[0], center[1] - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                        break

        if print_enable:
            cv2.imshow("Traffic Light Debug", replica)

        return result_color, center_y


# --- [ì‹œìŠ¤í…œ ì´ˆê¸°í™”] ---
try:
    ser = serial.Serial(ARDUINO_PORT, BAUDRATE, timeout=0)
    time.sleep(2.0)
    print(f"Arduino Connected on {ARDUINO_PORT}")
except Exception as e:
    print(f"Serial Error: {e}")
    ser = None

lane_detector = al.LaneDetector(WIDTH, HEIGHT)
controller = al.PurePursuitController()
det = al.LaneDetector()

# ì¹´ë©”ë¼ ì„¤ì •
env = SmartCamera()
# [ì¤‘ìš”] ì¹´ë©”ë¼ í¬íŠ¸ ë²ˆí˜¸ í™•ì¸ (ì°¨ì„ :1, ì‹ í˜¸ë“±:2 ë“± í™˜ê²½ì— ë§ê²Œ)
ch_lane, ch_traffic = env.initial_setting(cam0port=1, cam1port=2, capnum=2)

# ì „ì—­ ë³€ìˆ˜
steering_history = []
HISTORY_LIMIT = 5
prev_left_fit, prev_right_fit = None, None
last_send_time = 0
send_interval = 0.05
kernel = np.ones((5, 5), np.uint8)


def main():
    global prev_left_fit, prev_right_fit, last_send_time, steering_history

    print("=== ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ê°€ë™ ===")
    print("ì„¤ì •: 0=ì£¼í–‰, 1=ì •ì§€")

    # ì´ˆê¸° ì°¨ì„  ê°’ (ì—ëŸ¬ ë°©ì§€ìš©)
    prev_left_fit = np.array([0, 0, 150])
    prev_right_fit = np.array([0, 0, 450])

    # ìƒíƒœ ë³€ìˆ˜ëŠ” ë£¨í”„ ë°–ì—ì„œ ì„ ì–¸
    waiting_for_green = False

    try:
        while True:
            # 1. ì¹´ë©”ë¼ ë°ì´í„° ì½ê¸°
            ret_lane, frame_lane, ret_traffic, frame_traffic = env.camera_read(ch_lane, ch_traffic)
            if not ret_lane or not ret_traffic:
                print("ì¹´ë©”ë¼ ì˜ìƒ ì½ê¸° ì‹¤íŒ¨")
                break

            frame_lane = cv2.resize(frame_lane, (WIDTH, HEIGHT))
            frame_traffic = cv2.resize(frame_traffic, (WIDTH, HEIGHT))

            # ------------------------------------------------
            # [TASK A] ì‹ í˜¸ë“± ì¸ì‹ ë° ìƒíƒœ ì œì–´
            # ------------------------------------------------
            roi_traffic = apply_roi(frame_traffic, x_start=0, x_end=WIDTH, y_start=0, y_end=150)
            tl_color, tl_y_pos = env.object_detection_with_pos(roi_traffic, sample=5, print_enable=True)

            # [ìˆ˜ì •ë¨] ê¸°ë³¸ê°’: 0 (ì£¼í–‰)
            drive_mode = 0
            status_msg = "DRIVING"

            # ì‹ í˜¸ë“± ìƒíƒœ ë¨¸ì‹  ë¡œì§
            if waiting_for_green == False:
                # (1) ì£¼í–‰ ì¤‘ì¼ ë•Œ: ë¹¨ê°„ë¶ˆ ê°ì‹œ
                if tl_color == "RED":
                    if tl_y_pos < 230:  # ìƒë‹¨ì— ë¹¨ê°„ë¶ˆì´ ëœ¨ë©´
                        waiting_for_green = True  # ëŒ€ê¸° ëª¨ë“œ ì§„ì…
                        drive_mode = 1  # [ìˆ˜ì •ë¨] 1 (ì •ì§€)
                        print(f"ğŸš¨ [STOP] ë¹¨ê°„ë¶ˆ ê°ì§€ (Y={tl_y_pos}) -> ì •ì§€")
            else:
                # (2) ëŒ€ê¸° ì¤‘ì¼ ë•Œ: ì´ˆë¡ë¶ˆ ê°ì‹œ
                if tl_color == "GREEN":
                    waiting_for_green = False  # ëŒ€ê¸° ëª¨ë“œ í•´ì œ
                    drive_mode = 0  # [ìˆ˜ì •ë¨] 0 (ì£¼í–‰)
                    print("ğŸŸ¢ [GO] ì´ˆë¡ë¶ˆ ê°ì§€ -> ì¶œë°œ")
                else:
                    drive_mode = 1  # [ìˆ˜ì •ë¨] 1 (ê³„ì† ì •ì§€)
                    status_msg = "WAITING FOR GREEN"
                    print("â³ ì‹ í˜¸ ëŒ€ê¸° ì¤‘... (ì •ì§€ ìœ ì§€)")

            # ------------------------------------------------
            # [TASK B] ì°¨ì„  ì¸ì‹ (í•­ìƒ ì‹¤í–‰)
            # ------------------------------------------------
            # 2. ì´ì§„í™”
            _, green_mask = lane_detector.mask_green_floor(frame_lane)
            frame_lane_masked = lane_detector.erase_right_of_green(frame_lane, green_mask)
            combined = lane_detector.get_binary_hls(frame_lane_masked)

            # 3. ëª¨í´ë¡œì§€
            cleaned = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel)
            refined = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)

            # 4. í•„í„°ë§ ë° ìœˆë„ìš° íƒìƒ‰
            block_refined = lane_detector.block_filter(refined, nwindows=60, min_w=10, max_w=33)
            final_img = lane_detector.filter_by_shape(block_refined)

            window_img, _, left_fit, right_fit, _, _ = lane_detector.sliding_window(
                final_img, left_roi_pts, right_roi_pts, nwindows=60, margin=50, minpix=30
            )

            # 5. ì°¨ì„  ì˜ˆì¸¡ ë° ìŠ¤ë¬´ë”©
            left_fit, right_fit = lane_detector.predict_lane(left_fit, right_fit, lane_width=LANE_WIDTH_PIXELS)

            if lane_detector.sanity_check(left_fit, right_fit):
                prev_left_fit, prev_right_fit = left_fit, right_fit
            else:
                left_fit, right_fit = prev_left_fit, prev_right_fit

            # 6. ì¡°í–¥ê° ê³„ì‚°
            steering_angle = 0.0
            if left_fit is not None and right_fit is not None:
                raw_steer = controller.calculate_steering(left_fit, right_fit, WIDTH, HEIGHT)

                # ê°’ íŠ€ëŠ” í˜„ìƒ ë°©ì§€ (ìŠ¤ë¬´ë”©)
                if not steering_history:
                    steering_angle = raw_steer
                    steering_history.append(steering_angle)
                else:
                    avg_steering = sum(steering_history) / len(steering_history)
                    if abs(raw_steer - avg_steering) <= 150:
                        steering_angle = raw_steer
                        steering_history.append(steering_angle)
                        steering_history.pop(0)
                    else:
                        steering_angle = avg_steering  # ì´ìƒì¹˜ ë°œìƒ ì‹œ í‰ê· ê°’ ì‚¬ìš©

            # ------------------------------------------------
            # [TASK C] ì•„ë‘ì´ë…¸ ì „ì†¡ (ë””ë²„ê¹… ëª¨ë“œ)
            # ------------------------------------------------
            curr_time = time.time()

            # (ì¤‘ìš”) ì•„ë‘ì´ë…¸ ì—°ê²°ì´ ì•ˆ ë˜ì–´ ìˆì–´ë„ ë¡œê·¸ëŠ” ì°íˆê²Œ ìˆ˜ì •
            if (curr_time - last_send_time > send_interval):

                # ì •ì§€ ìƒíƒœ(1)ì¼ ë•ŒëŠ” ì¡°í–¥ê° 0ìœ¼ë¡œ ë³´ëƒ„
                if drive_mode == 1:
                    send_steer = 0.0
                else:
                    send_steer = steering_angle

                # [ì „ì†¡ í¬ë§·] "ì¡°í–¥ê°,ëª¨ë“œ\n"
                msg = f"{send_steer:.1f},{drive_mode}\n"

                # --- [ìˆ˜ì •] ë³´ë‚´ëŠ” ê°’ì„ ë¬´ì¡°ê±´ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤ ---
                if drive_mode == 0:
                    # 0 = ì£¼í–‰ (ì´ˆë¡ìƒ‰ ë©”ì‹œì§€)
                    print(f"ğŸš€ [ì£¼í–‰ì‹ í˜¸ ì „ì†¡] {msg.strip()} (Steer: {send_steer:.1f})")
                else:
                    # 1 = ì •ì§€ (ë¹¨ê°„ìƒ‰ ë©”ì‹œì§€)
                    print(f"â›” [ì •ì§€ì‹ í˜¸ ì „ì†¡] {msg.strip()} (RED LIGHT or WAIT)")
                # --------------------------------------------------

                if ser and ser.is_open:
                    ser.write(msg.encode())

                    if ser.in_waiting > 0:
                        ser.read(ser.in_waiting)

                last_send_time = curr_time

            # ------------------------------------------------
            # [TASK D] ì‹œê°í™”
            # ------------------------------------------------
            cv2.polylines(window_img, [np.int32(left_roi_pts)], True, (0, 0, 255), 2)
            cv2.polylines(window_img, [np.int32(right_roi_pts)], True, (255, 0, 0), 2)
            cv2.putText(window_img, f"Mode: {drive_mode} ({status_msg})", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(window_img, f"Steer: {steering_angle:.1f}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            cv2.imshow("Lane Tracking (Cam1)", window_img)
            # cv2.imshow("Traffic (Cam2)", frame_traffic) # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except Exception as e:
        print(f"Main Loop Error: {e}")

    finally:
        # ì¢…ë£Œ ì‹œ ì•ˆì „í•˜ê²Œ ì •ì§€ ëª…ë ¹ ì „ì†¡ (1: ì •ì§€)
        if ser and ser.is_open:
            ser.write("0.0,1\n".encode())
            ser.close()
            print("System Shutdown - Motors Stopped")
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()